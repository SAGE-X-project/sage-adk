global:
  resolve_timeout: 5m
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@example.com'
  smtp_auth_username: 'alerts@example.com'
  smtp_auth_password: 'your-app-password'
  smtp_require_tls: true

# Templates
templates:
  - '/etc/alertmanager/*.tmpl'

# Route tree
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'

  routes:
    # Critical alerts - immediate notification
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 10s
      repeat_interval: 1h

    # Warning alerts - less frequent notifications
    - match:
        severity: warning
      receiver: 'warning-alerts'
      group_wait: 30s
      repeat_interval: 4h

    # Info alerts - daily digest
    - match:
        severity: info
      receiver: 'info-alerts'
      group_wait: 5m
      repeat_interval: 24h

# Receivers
receivers:
  - name: 'default'
    email_configs:
      - to: 'team@example.com'
        headers:
          Subject: '[SAGE ADK] Alert: {{ .GroupLabels.alertname }}'

  - name: 'critical-alerts'
    email_configs:
      - to: 'oncall@example.com'
        headers:
          Subject: '[CRITICAL] SAGE ADK: {{ .GroupLabels.alertname }}'
    # Slack webhook (example)
    # slack_configs:
    #   - api_url: 'YOUR_SLACK_WEBHOOK_URL'
    #     channel: '#critical-alerts'
    #     title: 'SAGE ADK Critical Alert'
    #     text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ end }}'
    # PagerDuty (example)
    # pagerduty_configs:
    #   - service_key: 'YOUR_PAGERDUTY_KEY'

  - name: 'warning-alerts'
    email_configs:
      - to: 'team@example.com'
        headers:
          Subject: '[WARNING] SAGE ADK: {{ .GroupLabels.alertname }}'
    # Slack webhook
    # slack_configs:
    #   - api_url: 'YOUR_SLACK_WEBHOOK_URL'
    #     channel: '#warnings'

  - name: 'info-alerts'
    email_configs:
      - to: 'team@example.com'
        headers:
          Subject: '[INFO] SAGE ADK Daily Digest'

# Inhibition rules (suppress alerts when others are firing)
inhibit_rules:
  # Suppress warning if critical is firing for same alert
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']

  # Suppress all alerts if agent is down
  - source_match:
      alertname: 'AgentDown'
    target_match_re:
      alertname: '.*'
    equal: ['instance']
